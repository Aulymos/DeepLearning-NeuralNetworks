{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f65a1d",
   "metadata": {},
   "source": [
    "# Using TensorFlow like Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b220b59",
   "metadata": {},
   "source": [
    "## Tensors and Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd1e0059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 20:41:12.122388: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-18 20:41:12.122983: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# import the lib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "346c07ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 20:41:38.797738: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-18 20:41:38.798323: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-18 20:41:38.798539: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-8E5U3B3): /proc/driver/nvidia/version does not exist\n",
      "2021-11-18 20:41:38.803404: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e223399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40cefa1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor variable\n",
    "t = tf.constant([\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0]\n",
    "])\n",
    "\n",
    "# show the shape of the tensor\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d53980a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_scalar = tf.constant(42)\n",
    "\n",
    "t_scalar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6902386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 7.,  8.],\n",
       "       [11., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing the tensor\n",
    "t_new = tf.constant([\n",
    "    [1., 2., 3., 4.],\n",
    "    [5., 6., 7., 8.],\n",
    "    [9., 10., 11., 12.],\n",
    "    [13., 14, 15., 16]\n",
    "])\n",
    "\n",
    "t_new[1:3, 2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7076429",
   "metadata": {},
   "source": [
    "### operations - add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed89b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two tensors for operations\n",
    "x = tf.constant([\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1]\n",
    "])\n",
    "y = tf.constant([\n",
    "    [2, 2, 2],\n",
    "    [2, 2, 2],\n",
    "    [2, 2, 2]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a621993b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3 3 3]\n",
      " [3 3 3]\n",
      " [3 3 3]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "add_result = tf.add(x, y)\n",
    "print(add_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1641c0cc",
   "metadata": {},
   "source": [
    "### operations - square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8449deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = add_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdecf98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[9, 9, 9],\n",
       "       [9, 9, 9],\n",
       "       [9, 9, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abebad4",
   "metadata": {},
   "source": [
    "### operations - multiply  (multiply each pair of the elements on the same coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c49762e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[6, 6, 6],\n",
       "       [6, 6, 6],\n",
       "       [6, 6, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply(y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6c738c",
   "metadata": {},
   "source": [
    "### operations - subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "268c8c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.subtract(z, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b0fb05",
   "metadata": {},
   "source": [
    "### operations - float divide (divide each pair of elements on the same coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e67386df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float64, numpy=\n",
       "array([[1.5, 1.5, 1.5],\n",
       "       [1.5, 1.5, 1.5],\n",
       "       [1.5, 1.5, 1.5]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.divide(z, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185472ee",
   "metadata": {},
   "source": [
    "### operations - int divide (divide each pair of elements on the same coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3504fdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z // y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070d0b5f",
   "metadata": {},
   "source": [
    "### operations - add n many objects each of which have the same shape and type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18f7eaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[3, 3, 3],\n",
       "       [3, 3, 3],\n",
       "       [3, 3, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef2cd27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2133e6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[2, 2, 2],\n",
       "       [2, 2, 2],\n",
       "       [2, 2, 2]], dtype=int32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dd084b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[6, 6, 6],\n",
       "       [6, 6, 6],\n",
       "       [6, 6, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.add_n([x, y, z])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d737ecc4",
   "metadata": {},
   "source": [
    "### operations - scale a tensor with a scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2aa877a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[3, 3, 3],\n",
       "       [3, 3, 3],\n",
       "       [3, 3, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a74c904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[6, 6, 6],\n",
       "       [6, 6, 6],\n",
       "       [6, 6, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.scalar_mul(2, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a924e30e",
   "metadata": {},
   "source": [
    "### operations - modulo operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "399129d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[2, 2, 2],\n",
       "       [2, 2, 2],\n",
       "       [2, 2, 2]], dtype=int32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f9655f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[3, 3, 3],\n",
       "       [3, 3, 3],\n",
       "       [3, 3, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7800cfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.floormod(z, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c44fd3b",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b330b7ec",
   "metadata": {},
   "source": [
    "### variables - define a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d205829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a tensor variable\n",
    "\n",
    "v = tf.Variable([\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0]\n",
    "])\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d03a264",
   "metadata": {},
   "source": [
    "### variables - assign() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d52c824f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change all the elements of a variable\n",
    "\n",
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8d11e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change a specific element by indexing\n",
    "\n",
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f80c5753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change specific elements by index slicing\n",
    "\n",
    "v[:, 2].assign([0.0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8436c640",
   "metadata": {},
   "source": [
    "## Customizing Models and Training Alogrithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ad4ef",
   "metadata": {},
   "source": [
    "### Saving and Loading models containing Custom Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d31ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 13:00:23.827156: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-30 13:00:23.827310: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# import the libs\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load the dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# split the dataset into training and test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "\n",
    "# obtain the validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "# scale the training, validation and test instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c82e6dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Huber Loss function\n",
    "\n",
    "def huber_fn(y_true, y_pred):\n",
    "    \n",
    "    error = y_true - y_pred\n",
    "    \n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    \n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    \n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79de003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 13:02:33.729358: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-30 13:02:33.730307: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-30 13:02:33.730573: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-8E5U3B3): /proc/driver/nvidia/version does not exist\n",
      "2021-11-30 13:02:33.738776: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the graph of Huber Loss \n",
    "\n",
    "## import the lib\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "## create the plot with a specific size \n",
    "plt.figure(figsize=(8, 3.5))\n",
    "\n",
    "z = np.linspace(-4, 4, 200)\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a03715d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "\n",
    "## set the input shape\n",
    "input_shape = X_train.shape[1: ]\n",
    "\n",
    "## model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                      input_shape=input_shape),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d41b9aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad3e736f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5579 - mae: 0.9123 - val_loss: 0.3826 - val_mae: 0.6765\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2192 - mae: 0.5171 - val_loss: 0.3174 - val_mae: 0.6048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f33a08b39a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "         validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cecd66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(\"my_model_with_a_custom_loss.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02627f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
    "                               custom_objects={\"huber_fn\": huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "524e3193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2065 - mae: 0.4987 - val_loss: 0.2578 - val_mae: 0.5441\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.1981 - mae: 0.4870 - val_loss: 0.1976 - val_mae: 0.4776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3353cfd820>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the loaded model\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "         validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a54f98",
   "metadata": {},
   "source": [
    "### define a configured loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b37814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function for creating huber loss with a different error threshold \n",
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab8add57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00877629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2170 - mae: 0.4824 - val_loss: 0.2061 - val_mae: 0.4659\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2106 - mae: 0.4757 - val_loss: 0.2322 - val_mae: 0.4787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3353da3940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "         validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b09b33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model \n",
    "model.save(\"my_model_with_a_custom_loss_threshold_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58e3d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model with specified custom objects\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\", \n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bd4e3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2073 - mae: 0.4709 - val_loss: 0.2107 - val_mae: 0.4532\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2052 - mae: 0.4670 - val_loss: 0.2138 - val_mae: 0.4655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3380efb910>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the loaded model\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "         validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed03ee8",
   "metadata": {},
   "source": [
    "### Huber Loss Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8a31930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the class \n",
    "class HuberLoss(keras.losses.Loss):\n",
    "    \n",
    "    # the attributes\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    # call() method which returns the huber loss \n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    \n",
    "    # get_config() method which returns the \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6edbeb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6493 - mae: 0.8563 - val_loss: 0.4256 - val_mae: 0.5946\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2424 - mae: 0.5098 - val_loss: 0.3259 - val_mae: 0.5335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3380a6a970>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a model \n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                      input_shape=input_shape),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=HuberLoss(2.0), optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "         validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25bbfd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(\"my_model_with_a_custom_loss_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afc91da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\", \n",
    "                               custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40237300",
   "metadata": {},
   "source": [
    "### Custom Activation Functions, Initializers, Regularizers and Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28036944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 14:22:46.938835: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-02 14:22:46.939149: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# import the libs\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eade5931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear previous sessions\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d100508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset and create training, validation and test sets\n",
    "\n",
    "## import the libs\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## load the dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "## split the dataset into training and test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "\n",
    "## obtain the validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "## scale the training, validation and test instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "## fit and transform\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29575790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all the custom functions\n",
    "\n",
    "## custom activation function for layer initialisation: softplus \n",
    "def my_softplus(z):\n",
    "    \n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "## custom layer initializer: glorot\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    \n",
    "    stddev = tf.sqrt(2.0 / (shape[0] + shape[1]))\n",
    "    \n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "## custom layer regularizer: l1\n",
    "def my_l1_regularizer(weights):\n",
    "    \n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "## custom constraint for layer weights: positive weights\n",
    "def my_positive_weights(weights):\n",
    "    \n",
    "    return tf.where(weights < 0, tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b69e29df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of creating an output layer with the arguments of the above custom parameters\n",
    "\n",
    "layer = keras.layers.Dense(30, activation=my_softplus,\n",
    "                          kernel_initializer=my_glorot_initializer,\n",
    "                          kernel_regularizer=my_l1_regularizer,\n",
    "                          kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d843a979",
   "metadata": {},
   "source": [
    "### Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb87c6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 10:35:23.631723: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-05 10:35:23.631983: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# import the libs\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21d4a1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the previous sessions\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# set the random seed\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca4ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data set\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# split the dataset into training and test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "\n",
    "# obtain the validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "# scale the training, validation and test instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0528a9f3",
   "metadata": {},
   "source": [
    "#### streaming Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9268b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two results\n",
    "res_1, res_2 = [0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c238f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a precision object\n",
    "precision = keras.metrics.Precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6dc47cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the 2 results \n",
    "precision(res_1, res_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebeb7cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52cd87e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c668274",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1039c61c",
   "metadata": {},
   "source": [
    "#### streaming Metrics - self-defined Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0413a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb10ed76",
   "metadata": {},
   "source": [
    "### Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a170f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 13:23:31.338287: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-10 13:23:31.339355: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# import the libs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13539094",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# clear the previous sessions\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# set the random seed\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d57e7c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data set\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# split the dataset into training and test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "\n",
    "# obtain the validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "# scale the training, validation and test instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36c96b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define subclass of custom Dense layer\n",
    "\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ffbb955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 13:23:45.791982: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-10 13:23:45.792990: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-10 13:23:45.793224: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-8E5U3B3): /proc/driver/nvidia/version does not exist\n",
      "2021-12-10 13:23:45.798134: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# create a Sequential Model using the custom layer\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=X_train.shape[1: ]),\n",
    "    MyDense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e027722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.2563 - val_loss: 0.9472\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6485 - val_loss: 0.6219\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5473726987838745"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "         validation_data=(X_valid_scaled, y_valid))\n",
    "\n",
    "# evaluate the model\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4083473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(\"my_model_with_a_custom_layer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f9d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the layer\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_layer.h5\",\n",
    "                               custom_objects={\"MyDense\": MyDense})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4279ea",
   "metadata": {},
   "source": [
    "#### Custom Layers: Multi-layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a56573eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a custom Multi-layer class\n",
    "\n",
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    \n",
    "    # call() method\n",
    "    def call(self, X):\n",
    "        \n",
    "        X1, X2 = X\n",
    "        print(\"X1.shape: {} X2.shape: {}\".format(X1.shape, X2.shape))\n",
    "        return X1 + X2, X1 * X2\n",
    "    \n",
    "    # compute the output shape\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        \n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3877607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape: (None, 2) X2.shape: (None, 2)\n"
     ]
    }
   ],
   "source": [
    "# calling example\n",
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257acba9",
   "metadata": {},
   "source": [
    "#### Custom Layers: actual data to the custom MultiLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d80dd698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11610, 4), (11610, 4))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a data split function\n",
    "\n",
    "def split_data(data):\n",
    "    \n",
    "    # obtain the number of columns of the data\n",
    "    columns_count = data.shape[-1]\n",
    "    # obtain the split index\n",
    "    half = columns_count // 2\n",
    "    \n",
    "    return data[:, : half], data[:, half: ]\n",
    "\n",
    "# run the defined function to obtain the splitted data\n",
    "X_train_scaled_A, X_train_scaled_B = split_data(X_train_scaled)\n",
    "X_valid_scaled_A, X_valid_scaled_B = split_data(X_valid_scaled)\n",
    "X_test_scaled_A, X_test_scaled_B = split_data(X_test_scaled)\n",
    "\n",
    "# print the splitted data shapes\n",
    "X_train_scaled_A.shape, X_train_scaled_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cf8d16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape: (11610, 4) X2.shape: (11610, 4)\n"
     ]
    }
   ],
   "source": [
    "# show the specified shapes by the created class object\n",
    "output1, output2 = MyMultiLayer()((X_train_scaled_A, X_train_scaled_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e627ad14",
   "metadata": {},
   "source": [
    "#### Custom Layers: ** Just a game **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce42dfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 17:32:00.750772: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-10 17:32:00.751266: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# import the libs\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49faad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the previous session\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b0a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seed\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aef7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data and split into training, validation and test sets\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# split the dataset into training and test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "\n",
    "# obtain the validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "# scale the training, validation and test instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae89065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom multi-layer class\n",
    "\n",
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    \n",
    "    # call() method\n",
    "    def call(self, X):\n",
    "        \n",
    "        X1, X2 = X\n",
    "        print(\"X1.shape: {} X2.shape: {}\".format(X1.shape, X2.shape))\n",
    "        return X1 + X2, X1 * X2\n",
    "    \n",
    "    # compute the output shape\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        \n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c62128cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11610, 4), (11610, 4))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define data splitting function\n",
    "\n",
    "def split_data(data):\n",
    "    \n",
    "    # obtain the number of columns of the data\n",
    "    columns_count = data.shape[-1]\n",
    "    # obtain the split index\n",
    "    half = columns_count // 2\n",
    "    \n",
    "    return data[:, : half], data[:, half: ]\n",
    "\n",
    "# run the defined function to obtain the splitted data\n",
    "X_train_scaled_A, X_train_scaled_B = split_data(X_train_scaled)\n",
    "X_valid_scaled_A, X_valid_scaled_B = split_data(X_valid_scaled)\n",
    "X_test_scaled_A, X_test_scaled_B = split_data(X_test_scaled)\n",
    "\n",
    "# print the splitted data shapes\n",
    "X_train_scaled_A.shape, X_train_scaled_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2ea8ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape: (None, 4) X2.shape: (None, 4)\n"
     ]
    }
   ],
   "source": [
    "# establish a model with custom multi-layer\n",
    "\n",
    "## input layers \n",
    "input_A = keras.layers.Input(shape=X_train_scaled_A.shape[-1])\n",
    "input_B = keras.layers.Input(shape=X_train_scaled_B.shape[-1])\n",
    "\n",
    "## hidden lyaers shapes\n",
    "hidden_A, hidden_B = MyMultiLayer()((input_A, input_B))\n",
    "\n",
    "## hidden layers respectively\n",
    "hidden_A = keras.layers.Dense(30, activation=\"selu\")(hidden_A)\n",
    "hidden_B = keras.layers.Dense(30, activation=\"selu\")(hidden_B)\n",
    "\n",
    "## output layers with concatenating hidden layer shapes together\n",
    "concat = keras.layers.Concatenate()((hidden_A, hidden_B))\n",
    "\n",
    "## output layer\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "## model creation\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f3cb979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "\n",
    "model.compile(loss='mse', optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06af31ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "X1.shape: (None, 4) X2.shape: (None, 4)\n",
      "X1.shape: (None, 4) X2.shape: (None, 4)\n",
      "322/363 [=========================>....] - ETA: 0s - loss: 2.0718X1.shape: (None, 4) X2.shape: (None, 4)\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.9503 - val_loss: 1.7614\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9878 - val_loss: 1.7017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f88205cbd00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model with splitted scaled training data\n",
    "\n",
    "model.fit((X_train_scaled_A, X_train_scaled_B), y_train, epochs=2,\n",
    "         validation_data=((X_valid_scaled_A, X_valid_scaled_B), y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e3fa9f",
   "metadata": {},
   "source": [
    "#### custom layers: ** different behavior during training **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a0140cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# clear the previous session\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# load the data and split into training, validation and test sets\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# split the dataset into training and test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "\n",
    "# obtain the validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "# scale the training, validation and test instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc0f2532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a Gaussian Noise adding object class\n",
    "\n",
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "106cce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model with Gaussian Noise adding \n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    AddGaussianNoise(stddev=1.0),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a31e0333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.3857 - val_loss: 7.6082\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0571 - val_loss: 4.4597\n",
      "162/162 [==============================] - 0s 789us/step - loss: 0.7560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7559615969657898"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "\n",
    "# fit\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "         validation_data=(X_valid_scaled, y_valid))\n",
    "\n",
    "#evaluate\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f021de",
   "metadata": {},
   "source": [
    "### Custom Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c6a35a",
   "metadata": {},
   "source": [
    "#### custom Models: ** Residual Blocks **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d4dcdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 20:08:48.015477: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-10 20:08:48.015791: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# import the libs\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745ad552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the previous session\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2876418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "986d8dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset and create training, validation and test datasets\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# split the dataset into training and test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "\n",
    "# obtain the validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "# scale the training, validation and test instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7864604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Residual Block layer class\n",
    "\n",
    "class ResidualBlock(keras.layers.Layer):\n",
    "    \n",
    "    # initialise the layer strucutre\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\", \n",
    "                                         kernel_initializer=\"he_normal\")\n",
    "                      for _ in range(n_layers)]\n",
    "    \n",
    "    # call method\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        \n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b62538eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Residual-Block model class \n",
    "\n",
    "class ResidualRegressor(keras.models.Model):\n",
    "    \n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
    "                                         kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "       \n",
    "        Z = self.hidden1(inputs)\n",
    "        \n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "       \n",
    "        Z = self.block2(Z)\n",
    "        \n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e13c245b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 08:04:36.069899: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-11 08:04:36.071477: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-11 08:04:36.071761: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-8E5U3B3): /proc/driver/nvidia/version does not exist\n",
      "2021-12-11 08:04:36.077517: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 9.1325\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0578\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8868\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5831\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6462\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.6512\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = ResidualRegressor(1)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "\n",
    "# fit history\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "\n",
    "# evaluate the score\n",
    "score = model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f9fc428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40105268],\n",
       "       [2.02627   ],\n",
       "       [4.160809  ],\n",
       "       ...,\n",
       "       [1.6198759 ],\n",
       "       [3.3076649 ],\n",
       "       [3.9956803 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the predictions\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbc2e6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 08:05:50.777138: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn, dense_2_layer_call_and_return_conditional_losses, dense_3_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_custom_model.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_custom_model.ckpt/assets\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "\n",
    "model.save(\"my_custom_model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ec6fc",
   "metadata": {},
   "source": [
    "### Losses and Metrics Based on Model Internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d736fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libs\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1002e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the previous session\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4487593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seed\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7d0c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset and create training, validation and test datasets\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# split the dataset into training and test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "\n",
    "# obtain the validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "# scale the training, validation and test instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c544c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the custom network regressor with custom losses based on model internals\n",
    "\n",
    "class ReconstructingRegressor(keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "                                          kernel_initializer=\"lecun_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        self.reconstruction_mean = keras.metrics.Mean(name=\"reconstruction_error\")\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        #super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        if training:\n",
    "            result = self.reconstruction_mean(recon_loss)\n",
    "            self.add_metric(result)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99a4b83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 0.7885 - reconstruction_error: 1.0474\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4126 - reconstruction_error: 0.4022\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3851 - reconstruction_error: 0.3032\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3650 - reconstruction_error: 0.2560\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3545 - reconstruction_error: 0.2224\n",
      "162/162 [==============================] - 0s 992us/step - loss: 0.3529 - reconstruction_error: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3529241979122162, 0.0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "model = ReconstructingRegressor(1)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "\n",
    "# history fit\n",
    "model.fit(X_train_scaled, y_train, epochs=5)\n",
    "\n",
    "# evaluate the model\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3dd4054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model_with_internal_loss.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model_with_internal_loss.ckpt/assets\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "\n",
    "model.save(\"my_model_with_internal_loss.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1029dcbd",
   "metadata": {},
   "source": [
    "### Computing Gradients Using Autodiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665f0129",
   "metadata": {},
   "source": [
    "#### set a toy function: 3*w1**2 + 2*w1*w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19275562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the toy function\n",
    "\n",
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63838956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de288929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.000003007075065\n",
      "10.000000003174137\n"
     ]
    }
   ],
   "source": [
    "# calculate the gradients by an proximation of each partial derivative\n",
    "\n",
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "print((f(w1 + eps, w2) - f(w1, w2)) / eps)\n",
    "print((f(w1, w2 + eps) - f(w1, w2)) / eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eff9c96",
   "metadata": {},
   "source": [
    "#### Using tf.GradientTape().gradient() method to calculate the Gradients for the toy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f8c3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 14:41:07.551979: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-11 14:41:07.552162: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# import the lib\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b05e7fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the variables w1, w2 with tensorflow Variable\n",
    "w1, w2 = tf.Variable(5.0), tf.Variable(3.0)\n",
    "\n",
    "# create tf.GradientTape context\n",
    "with tf.GradientTape() as tape:\n",
    "    \n",
    "    # assign the toy function in the context\n",
    "    z = f(w1, w2)\n",
    "    \n",
    "# use tape.gradient(function, [variable list]) method to obtain the gradients\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ca7042e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6166e8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_84/4173795235.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdz_dw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdz_dw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/MachineLearning/Chapter12/env/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \"\"\"\n\u001b[1;32m   1031\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m       raise RuntimeError(\"A non-persistent GradientTape can only be used to \"\n\u001b[0m\u001b[1;32m   1033\u001b[0m                          \"compute one set of gradients (or jacobians)\")\n\u001b[1;32m   1034\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recording\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)"
     ]
    }
   ],
   "source": [
    "# the \"non-persistent\" problem of gradient() method\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22e95a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(36.0, shape=(), dtype=float32) tf.Tensor(10.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# to solve the above issue\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2)\n",
    "\n",
    "del tape\n",
    "\n",
    "print(dz_dw1, dz_dw2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cef9b2",
   "metadata": {},
   "source": [
    "#### when the operations is for tensors rather than variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41b039a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>, <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]\n"
     ]
    }
   ],
   "source": [
    "# define 2 constant tensors\n",
    "c1, c2 = tf.constant(5.0), tf.constant(3.0)\n",
    "\n",
    "# set GradientTape()\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "gradients = tape.gradient(z, [c1, c2])\n",
    "print(gradients)\n",
    "del tape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686a2bb",
   "metadata": {},
   "source": [
    "#### Second order partial derivatives by tf.GradientTape().gradient() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c81f6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>, <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z = f(w1, w2)\n",
    "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
    "hessians = [hessian_tape.gradient(jacobian, [w1, w2])\n",
    "            for jacobian in jacobians]\n",
    "del hessian_tape\n",
    "\n",
    "print(jacobians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf71e68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>, <tf.Tensor: shape=(), dtype=float32, numpy=2.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]\n"
     ]
    }
   ],
   "source": [
    "print(hessians)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059431b",
   "metadata": {},
   "source": [
    "#### stop_gradient() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cf5d285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    \n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c09c442",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebcd0788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]\n"
     ]
    }
   ],
   "source": [
    "print(gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15a55a0",
   "metadata": {},
   "source": [
    "#### numerical issues for large inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "075d8132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a custom activation \n",
    "\n",
    "def my_softplus(z):\n",
    "    \n",
    "    return tf.math.log(tf.exp(z) + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05303b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=nan>]\n"
     ]
    }
   ],
   "source": [
    "# define a variable \n",
    "x = tf.Variable(100.0)\n",
    "\n",
    "# set the context\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "# try to obtain the gradients\n",
    "gradient = tape.gradient(z, [x])\n",
    "\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68d9c0b",
   "metadata": {},
   "source": [
    "## TensorFlow Functions and Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febfb27a",
   "metadata": {},
   "source": [
    "### tf.function() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56d68035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a normal python function\n",
    "\n",
    "def cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "559d69de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result of cube(2)\n",
    "\n",
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c163791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the function with tf.constant()\n",
    "\n",
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4367d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tf.function() to cover the python function\n",
    "\n",
    "tf_cube = tf.function(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9be2b889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x7f533f529af0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc87f39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f833e45f",
   "metadata": {},
   "source": [
    "### @tf.function decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e9259f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5175b36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube.python_function(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c0d6eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb4cfc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5.0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.where(False, 1.5, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35967696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.5>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.where(False, 5.0, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5833f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
